{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "from psm_utils.psm import PSM\n",
    "from psm_utils.psm_list import PSMList\n",
    "from psm_utils.io import write_file\n",
    "from deeplc import FeatExtractor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras import callbacks\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense, Flatten\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding by atomic composition \n",
    "\n",
    "infile = pd.read_csv(\"/home/emmy/Notebooks2/MQ_alignment_output/evidence_aligned_6.csv\") #hier eigen aligned csv file aanroepen\n",
    "infile.head()\n",
    "psm_list = [] #psm_list is type object \n",
    "for idx,row in infile.iterrows():\n",
    "    seq = row[\"Sequence\"]\n",
    "    charge = row[\"Charge\"]  \n",
    "\n",
    "    peptidoform = f\"{seq}/{charge}\"\n",
    "\n",
    "    psm_list.append(PSM(peptidoform=peptidoform,spectrum_id=idx))\n",
    "    \n",
    "psm_list = PSMList(psm_list=psm_list)\n",
    "\n",
    "feat_extractor = FeatExtractor()\n",
    "matrices = feat_extractor.encode_atoms(psm_list, list(range(len(psm_list))), predict_ccs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>409.181586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>675.752631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593.085242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>682.043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>492.912110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CCS\n",
       "0  409.181586\n",
       "1  675.752631\n",
       "2  593.085242\n",
       "3  682.043900\n",
       "4  492.912110"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/emmy/Notebooks2/MQ_alignment_output/evidence_aligned_6.csv\") #reading in the data\n",
    "ccs_df = data[['CCS']]\n",
    "ccs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1148760, 60, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(list(matrices[\"matrix\"].values())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1148760, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(list(matrices[\"matrix_all\"].values())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.stack(list(matrices[\"matrix\"].values()))\n",
    "matrix_all = np.stack(list(matrices[\"matrix_all\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "matrix_train, matrix_test, matrix_all_train, matrix_all_test, ccs_train, ccs_test = train_test_split(matrix, matrix_all, ccs_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split the training data into training and validation sets if needed\n",
    "matrix_train, matrix_val, matrix_all_train, matrix_all_val, ccs_train, ccs_val = train_test_split(matrix_train, matrix_all_train, ccs_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Peptide sequence: [ 96 148  24  33   0   0  20   0   0   0   0   3] CCS value: 542.3662\n",
      "Peptide sequence: [46 69 11 10  0  0  8  0  0  0  0  2] CCS value: 336.038086\n",
      "Peptide sequence: [57 96 14 18  0  0 11  0  0  0  0  2] CCS value: 375.9927733333333\n",
      "Peptide sequence: [ 84 137  23  32   1   0  19   0   0   0   0   2] CCS value: 473.0402284615385\n",
      "Peptide sequence: [ 67 108  18  23   1   0  15   0   0   0   0   2] CCS value: 421.12067\n"
     ]
    }
   ],
   "source": [
    "#checking of the correct ccs value is coupled to the correct peptide sequence\n",
    "\n",
    "if len(matrix_all_train) > 0 and len(ccs_train) > 0:\n",
    "    print(\"Train set:\")\n",
    "    for i in range(5):\n",
    "        print(\"Peptide sequence:\", matrix_all_train[i], \"CCS value:\", ccs_train['CCS'].iloc[i])\n",
    "else:\n",
    "    print(\"Empty datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 19.5854 - val_loss: 13.4270\n",
      "Epoch 2/10\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 14.3132 - val_loss: 13.5223\n",
      "Epoch 3/10\n",
      "3231/3231 [==============================] - 24s 8ms/step - loss: 13.9334 - val_loss: 14.3406\n",
      "Epoch 4/10\n",
      "3231/3231 [==============================] - 21s 7ms/step - loss: 13.4897 - val_loss: 16.4553\n",
      "Epoch 5/10\n",
      "3231/3231 [==============================] - 21s 7ms/step - loss: 13.2754 - val_loss: 12.5026\n",
      "Epoch 6/10\n",
      "3231/3231 [==============================] - 21s 6ms/step - loss: 13.0308 - val_loss: 15.0347\n",
      "Epoch 7/10\n",
      "3231/3231 [==============================] - 21s 6ms/step - loss: 12.9214 - val_loss: 12.1725\n",
      "Epoch 8/10\n",
      "3231/3231 [==============================] - 21s 6ms/step - loss: 12.7763 - val_loss: 12.3239\n",
      "Epoch 9/10\n",
      "3231/3231 [==============================] - 21s 6ms/step - loss: 12.7292 - val_loss: 12.2417\n",
      "Epoch 10/10\n",
      "3231/3231 [==============================] - 21s 7ms/step - loss: 12.6278 - val_loss: 12.3489\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "# Assuming your input shapes\n",
    "matrix_shape = (1148760, 60, 6)\n",
    "matrix_all_shape = (1148760, 12)\n",
    "\n",
    "# Define input layers for each matrix\n",
    "input_matrix = Input(shape=(matrix_shape[1], matrix_shape[2]), name='matrix_input')\n",
    "input_matrix_all = Input(shape=(matrix_all_shape[1],), name='matrix_input_all')\n",
    "\n",
    "# Flatten the input matrices\n",
    "flattened_matrix = Flatten()(input_matrix)\n",
    "flattened_matrix_all = input_matrix_all  # No need to flatten\n",
    "\n",
    "# Concatenate the flattened and non-flattened outputs\n",
    "concatenated_outputs = Concatenate()([flattened_matrix, flattened_matrix_all])\n",
    "\n",
    "\n",
    "dense1 = Dense(units=512, activation = \"relu\")(concatenated_outputs)\n",
    "dense2 = Dense(units=512, activation = \"relu\")(dense1)\n",
    "dense3 = Dense(units=512, activation = \"relu\")(dense2)\n",
    "output = Dense(units=1)(dense3)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input_matrix, input_matrix_all], outputs=output)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae'\n",
    ")\n",
    "# Train the model with your input and output data\n",
    "history = model.fit([matrix_train, matrix_all_train], ccs_train, epochs=10, batch_size=256, validation_data=([matrix_val, matrix_all_val], ccs_val))\n",
    "\n",
    "\n",
    "# convert the training history to a dataframe\n",
    "history_df_2 = pd.DataFrame(history.history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss: 12.172513008117676\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum validation loss: {}\".format(history_df_2['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df_2.to_csv('history_2.csv', index=False) #save the history to a csv file for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 125/3231 [>.............................] - ETA: 32s - loss: 64.8568"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231/3231 [==============================] - 35s 11ms/step - loss: 19.5496 - val_loss: 15.8622\n",
      "Epoch 2/500\n",
      "3231/3231 [==============================] - 35s 11ms/step - loss: 14.3577 - val_loss: 13.0160\n",
      "Epoch 3/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 13.7708 - val_loss: 12.7879\n",
      "Epoch 4/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 13.4237 - val_loss: 12.9888\n",
      "Epoch 5/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 13.2281 - val_loss: 12.7121\n",
      "Epoch 6/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 13.0719 - val_loss: 12.4303\n",
      "Epoch 7/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 12.9920 - val_loss: 12.3545\n",
      "Epoch 8/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.9075 - val_loss: 12.4955\n",
      "Epoch 9/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.7433 - val_loss: 12.6163\n",
      "Epoch 10/500\n",
      "3231/3231 [==============================] - 35s 11ms/step - loss: 12.6992 - val_loss: 12.5004\n",
      "Epoch 11/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.6380 - val_loss: 12.2636\n",
      "Epoch 12/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.5533 - val_loss: 12.4407\n",
      "Epoch 13/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.4933 - val_loss: 12.3072\n",
      "Epoch 14/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.4211 - val_loss: 13.5818\n",
      "Epoch 15/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.3952 - val_loss: 11.9635\n",
      "Epoch 16/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.3426 - val_loss: 11.9351\n",
      "Epoch 17/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.3116 - val_loss: 12.3305\n",
      "Epoch 18/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.2534 - val_loss: 12.0855\n",
      "Epoch 19/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 12.2469 - val_loss: 12.6731\n",
      "Epoch 20/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 12.2234 - val_loss: 11.8746\n",
      "Epoch 21/500\n",
      "3231/3231 [==============================] - 27s 8ms/step - loss: 12.1518 - val_loss: 12.2206\n",
      "Epoch 22/500\n",
      "3231/3231 [==============================] - 23s 7ms/step - loss: 12.1294 - val_loss: 11.9049\n",
      "Epoch 23/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 12.1599 - val_loss: 12.8422\n",
      "Epoch 24/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 12.0650 - val_loss: 12.0251\n",
      "Epoch 25/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 12.0787 - val_loss: 13.3764\n",
      "Epoch 26/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 12.0268 - val_loss: 12.1028\n",
      "Epoch 27/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 12.0105 - val_loss: 11.8128\n",
      "Epoch 28/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 12.0072 - val_loss: 12.8847\n",
      "Epoch 29/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.9730 - val_loss: 11.9761\n",
      "Epoch 30/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.9344 - val_loss: 12.0002\n",
      "Epoch 31/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.9010 - val_loss: 11.6657\n",
      "Epoch 32/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.9144 - val_loss: 11.7567\n",
      "Epoch 33/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.8912 - val_loss: 11.8201\n",
      "Epoch 34/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.8613 - val_loss: 11.7083\n",
      "Epoch 35/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.8110 - val_loss: 11.7550\n",
      "Epoch 36/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.8705 - val_loss: 12.0307\n",
      "Epoch 37/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.8278 - val_loss: 11.6532\n",
      "Epoch 38/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.7751 - val_loss: 11.7301\n",
      "Epoch 39/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.7734 - val_loss: 11.6703\n",
      "Epoch 40/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.7817 - val_loss: 12.2410\n",
      "Epoch 41/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.7661 - val_loss: 12.2660\n",
      "Epoch 42/500\n",
      "3231/3231 [==============================] - 28s 9ms/step - loss: 11.7482 - val_loss: 11.8356\n",
      "Epoch 43/500\n",
      "3231/3231 [==============================] - 26s 8ms/step - loss: 11.7375 - val_loss: 11.7728\n",
      "Epoch 44/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.7262 - val_loss: 12.0660\n",
      "Epoch 45/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.7175 - val_loss: 12.0360\n",
      "Epoch 46/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.7329 - val_loss: 11.7883\n",
      "Epoch 47/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.6844 - val_loss: 11.7760\n",
      "Epoch 48/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.6971 - val_loss: 11.5910\n",
      "Epoch 49/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.6741 - val_loss: 11.8483\n",
      "Epoch 50/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.6707 - val_loss: 12.0081\n",
      "Epoch 51/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 11.6413 - val_loss: 11.5948\n",
      "Epoch 52/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.6466 - val_loss: 12.0479\n",
      "Epoch 53/500\n",
      "3231/3231 [==============================] - 26s 8ms/step - loss: 11.6427 - val_loss: 11.7639\n",
      "Epoch 54/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.6130 - val_loss: 12.1955\n",
      "Epoch 55/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.6067 - val_loss: 11.6766\n",
      "Epoch 56/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.6263 - val_loss: 11.5405\n",
      "Epoch 57/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.5805 - val_loss: 11.6463\n",
      "Epoch 58/500\n",
      "3231/3231 [==============================] - 28s 9ms/step - loss: 11.5999 - val_loss: 11.6608\n",
      "Epoch 59/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 11.5554 - val_loss: 11.9859\n",
      "Epoch 60/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.5593 - val_loss: 11.5777\n",
      "Epoch 61/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.5573 - val_loss: 11.5151\n",
      "Epoch 62/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.5641 - val_loss: 11.9903\n",
      "Epoch 63/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.5381 - val_loss: 11.7647\n",
      "Epoch 64/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.5335 - val_loss: 12.0052\n",
      "Epoch 65/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.5302 - val_loss: 12.2866\n",
      "Epoch 66/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.4967 - val_loss: 11.6678\n",
      "Epoch 67/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.5002 - val_loss: 11.6500\n",
      "Epoch 68/500\n",
      "3231/3231 [==============================] - 35s 11ms/step - loss: 11.4942 - val_loss: 11.6967\n",
      "Epoch 69/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.4863 - val_loss: 11.6745\n",
      "Epoch 70/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.4800 - val_loss: 11.5427\n",
      "Epoch 71/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.4770 - val_loss: 11.7343\n",
      "Epoch 72/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.4611 - val_loss: 11.5918\n",
      "Epoch 73/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.4866 - val_loss: 11.5018\n",
      "Epoch 74/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.4538 - val_loss: 11.4758\n",
      "Epoch 75/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.4398 - val_loss: 12.4435\n",
      "Epoch 76/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.4382 - val_loss: 11.5094\n",
      "Epoch 77/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.4173 - val_loss: 11.5539\n",
      "Epoch 78/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.4215 - val_loss: 12.0258\n",
      "Epoch 79/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.4248 - val_loss: 11.5906\n",
      "Epoch 80/500\n",
      "3231/3231 [==============================] - 24s 8ms/step - loss: 11.4279 - val_loss: 12.5220\n",
      "Epoch 81/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.3906 - val_loss: 11.5201\n",
      "Epoch 82/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.3942 - val_loss: 11.7362\n",
      "Epoch 83/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.3985 - val_loss: 11.8748\n",
      "Epoch 84/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.3859 - val_loss: 12.1266\n",
      "Epoch 85/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.3809 - val_loss: 11.4887\n",
      "Epoch 86/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.3666 - val_loss: 11.4870\n",
      "Epoch 87/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.3682 - val_loss: 11.5951\n",
      "Epoch 88/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 11.3502 - val_loss: 11.4684\n",
      "Epoch 89/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 11.3492 - val_loss: 11.3829\n",
      "Epoch 90/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.3294 - val_loss: 11.5076\n",
      "Epoch 91/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.3488 - val_loss: 11.5676\n",
      "Epoch 92/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 11.3280 - val_loss: 11.6887\n",
      "Epoch 93/500\n",
      "3231/3231 [==============================] - 27s 8ms/step - loss: 11.3172 - val_loss: 11.4329\n",
      "Epoch 94/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.3452 - val_loss: 11.7398\n",
      "Epoch 95/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 11.3140 - val_loss: 12.2448\n",
      "Epoch 96/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.3130 - val_loss: 11.3884\n",
      "Epoch 97/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.2985 - val_loss: 11.4161\n",
      "Epoch 98/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.2971 - val_loss: 11.7061\n",
      "Epoch 99/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.3020 - val_loss: 11.7299\n",
      "Epoch 100/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.2806 - val_loss: 11.7049\n",
      "Epoch 101/500\n",
      "3231/3231 [==============================] - 23s 7ms/step - loss: 11.2835 - val_loss: 11.4268\n",
      "Epoch 102/500\n",
      "3231/3231 [==============================] - 22s 7ms/step - loss: 11.2616 - val_loss: 11.4859\n",
      "Epoch 103/500\n",
      "3231/3231 [==============================] - 26s 8ms/step - loss: 11.2593 - val_loss: 12.0801\n",
      "Epoch 104/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.2753 - val_loss: 11.3855\n",
      "Epoch 105/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 11.2625 - val_loss: 11.5635\n",
      "Epoch 106/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.2542 - val_loss: 11.4964\n",
      "Epoch 107/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.2288 - val_loss: 11.6734\n",
      "Epoch 108/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.2345 - val_loss: 11.6106\n",
      "Epoch 109/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.2248 - val_loss: 11.5032\n",
      "Minimum validation loss: 11.382929801940918\n"
     ]
    }
   ],
   "source": [
    "#add early stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "# Assuming your input shapes\n",
    "matrix_shape = (1148760, 60, 6)\n",
    "matrix_all_shape = (1148760, 12)\n",
    "\n",
    "# Define input layers for each matrix\n",
    "input_matrix = Input(shape=(matrix_shape[1], matrix_shape[2]), name='matrix_input')\n",
    "input_matrix_all = Input(shape=(matrix_all_shape[1],), name='matrix_input_all')\n",
    "\n",
    "# Flatten the input matrices\n",
    "flattened_matrix = Flatten()(input_matrix)\n",
    "flattened_matrix_all = input_matrix_all  # No need to flatten\n",
    "\n",
    "# Concatenate the flattened and non-flattened outputs\n",
    "concatenated_outputs = Concatenate()([flattened_matrix, flattened_matrix_all])\n",
    "\n",
    "\n",
    "dense1 = Dense(units=512, activation = \"relu\")(concatenated_outputs)\n",
    "dense2 = Dense(units=512, activation = \"relu\")(dense1)\n",
    "dense3 = Dense(units=512, activation = \"relu\")(dense2)\n",
    "output = Dense(units=1)(dense3)\n",
    "\n",
    "# Create the model\n",
    "model2 = Model(inputs=[input_matrix, input_matrix_all], outputs=output)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae'\n",
    ")\n",
    "# Train the model with your input and output data\n",
    "history = model2.fit([matrix_train, matrix_all_train], ccs_train, epochs=500, batch_size=256, validation_data=([matrix_val, matrix_all_val], ccs_val), callbacks=[early_stopping])\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_csv('history.csv', index=False) #save the history to a csv file for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7180/7180 [==============================] - 5s 745us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict CCS values test set\n",
    "ccs_test[\"Model2_predictions\"] = model2.predict((matrix_test, matrix_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCS</th>\n",
       "      <th>Model2_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129919</th>\n",
       "      <td>420.248133</td>\n",
       "      <td>427.884583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129049</th>\n",
       "      <td>441.017200</td>\n",
       "      <td>430.113831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161312</th>\n",
       "      <td>550.032030</td>\n",
       "      <td>566.157043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15185</th>\n",
       "      <td>501.311247</td>\n",
       "      <td>500.421722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939427</th>\n",
       "      <td>520.231105</td>\n",
       "      <td>494.102081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CCS  Model2_predictions\n",
       "129919   420.248133          427.884583\n",
       "1129049  441.017200          430.113831\n",
       "161312   550.032030          566.157043\n",
       "15185    501.311247          500.421722\n",
       "939427   520.231105          494.102081"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_test.to_csv('ccs_test_model2.csv', index=False) #save the test set to a csv file for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 20.3715 - val_loss: 14.0726\n",
      "Epoch 2/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 15.0046 - val_loss: 13.5355\n",
      "Epoch 3/500\n",
      "3231/3231 [==============================] - 36s 11ms/step - loss: 14.3380 - val_loss: 13.4943\n",
      "Epoch 4/500\n",
      "3231/3231 [==============================] - 36s 11ms/step - loss: 13.7926 - val_loss: 14.5801\n",
      "Epoch 5/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 13.5000 - val_loss: 12.4856\n",
      "Epoch 6/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 13.2981 - val_loss: 12.2679\n",
      "Epoch 7/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 13.1088 - val_loss: 14.7322\n",
      "Epoch 8/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.9788 - val_loss: 13.0394\n",
      "Epoch 9/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.9095 - val_loss: 12.0974\n",
      "Epoch 10/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.8458 - val_loss: 13.3225\n",
      "Epoch 11/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.7785 - val_loss: 12.5979\n",
      "Epoch 12/500\n",
      "3231/3231 [==============================] - 36s 11ms/step - loss: 12.6746 - val_loss: 12.6609\n",
      "Epoch 13/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 12.5666 - val_loss: 12.0632\n",
      "Epoch 14/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.5635 - val_loss: 12.1562\n",
      "Epoch 15/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.5424 - val_loss: 13.4134\n",
      "Epoch 16/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 12.4711 - val_loss: 12.0690\n",
      "Epoch 17/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 12.4084 - val_loss: 13.8551\n",
      "Epoch 18/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.4182 - val_loss: 12.1294\n",
      "Epoch 19/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.3024 - val_loss: 12.3442\n",
      "Epoch 20/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.2733 - val_loss: 12.3986\n",
      "Epoch 21/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 12.2708 - val_loss: 12.3817\n",
      "Epoch 22/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 12.2028 - val_loss: 12.2818\n",
      "Epoch 23/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 12.1717 - val_loss: 13.0921\n",
      "Epoch 24/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 12.1811 - val_loss: 11.9356\n",
      "Epoch 25/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.1094 - val_loss: 13.5278\n",
      "Epoch 26/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.1146 - val_loss: 12.5289\n",
      "Epoch 27/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 12.0508 - val_loss: 12.1862\n",
      "Epoch 28/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 12.0451 - val_loss: 12.1024\n",
      "Epoch 29/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.9840 - val_loss: 11.9956\n",
      "Epoch 30/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.9775 - val_loss: 12.8901\n",
      "Epoch 31/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 11.9651 - val_loss: 12.7657\n",
      "Epoch 32/500\n",
      "3231/3231 [==============================] - 37s 12ms/step - loss: 11.9318 - val_loss: 11.6771\n",
      "Epoch 33/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.9046 - val_loss: 12.1172\n",
      "Epoch 34/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.8791 - val_loss: 11.9537\n",
      "Epoch 35/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.8952 - val_loss: 12.3309\n",
      "Epoch 36/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.8581 - val_loss: 12.1488\n",
      "Epoch 37/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.7987 - val_loss: 11.7660\n",
      "Epoch 38/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.8238 - val_loss: 11.9625\n",
      "Epoch 39/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.8070 - val_loss: 11.8032\n",
      "Epoch 40/500\n",
      "3231/3231 [==============================] - 35s 11ms/step - loss: 11.8063 - val_loss: 12.7098\n",
      "Epoch 41/500\n",
      "3231/3231 [==============================] - 35s 11ms/step - loss: 11.7442 - val_loss: 11.9538\n",
      "Epoch 42/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.7614 - val_loss: 11.8112\n",
      "Epoch 43/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.7242 - val_loss: 12.3789\n",
      "Epoch 44/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.7479 - val_loss: 12.3901\n",
      "Epoch 45/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.7079 - val_loss: 11.7161\n",
      "Epoch 46/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.7057 - val_loss: 11.8953\n",
      "Epoch 47/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.7010 - val_loss: 11.7942\n",
      "Epoch 48/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.6523 - val_loss: 11.6412\n",
      "Epoch 49/500\n",
      "3231/3231 [==============================] - 37s 11ms/step - loss: 11.6376 - val_loss: 11.6588\n",
      "Epoch 50/500\n",
      "3231/3231 [==============================] - 37s 12ms/step - loss: 11.6585 - val_loss: 11.7643\n",
      "Epoch 51/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.6297 - val_loss: 12.4911\n",
      "Epoch 52/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.6227 - val_loss: 11.9582\n",
      "Epoch 53/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.6002 - val_loss: 11.8757\n",
      "Epoch 54/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.5879 - val_loss: 11.7289\n",
      "Epoch 55/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.5819 - val_loss: 12.2900\n",
      "Epoch 56/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.5822 - val_loss: 11.8988\n",
      "Epoch 57/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.5779 - val_loss: 11.4889\n",
      "Epoch 58/500\n",
      "3231/3231 [==============================] - 35s 11ms/step - loss: 11.5642 - val_loss: 11.4192\n",
      "Epoch 59/500\n",
      "3231/3231 [==============================] - 38s 12ms/step - loss: 11.5495 - val_loss: 12.1935\n",
      "Epoch 60/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.5285 - val_loss: 11.7038\n",
      "Epoch 61/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.5428 - val_loss: 11.5370\n",
      "Epoch 62/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.5363 - val_loss: 11.8783\n",
      "Epoch 63/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.5224 - val_loss: 11.5038\n",
      "Epoch 64/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.4861 - val_loss: 14.2950\n",
      "Epoch 65/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.5291 - val_loss: 11.7763\n",
      "Epoch 66/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.4774 - val_loss: 11.5752\n",
      "Epoch 67/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 11.4773 - val_loss: 11.4871\n",
      "Epoch 68/500\n",
      "3231/3231 [==============================] - 36s 11ms/step - loss: 11.4689 - val_loss: 11.4879\n",
      "Epoch 69/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.4475 - val_loss: 11.7830\n",
      "Epoch 70/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.4562 - val_loss: 11.6588\n",
      "Epoch 71/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.4395 - val_loss: 11.3931\n",
      "Epoch 72/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.4451 - val_loss: 11.7696\n",
      "Epoch 73/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.4331 - val_loss: 11.5183\n",
      "Epoch 74/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.4206 - val_loss: 11.4873\n",
      "Epoch 75/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.4041 - val_loss: 12.0628\n",
      "Epoch 76/500\n",
      "3231/3231 [==============================] - 37s 11ms/step - loss: 11.3926 - val_loss: 12.8238\n",
      "Epoch 77/500\n",
      "3231/3231 [==============================] - 34s 11ms/step - loss: 11.3830 - val_loss: 11.8797\n",
      "Epoch 78/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.3765 - val_loss: 11.4963\n",
      "Epoch 79/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.3674 - val_loss: 11.5009\n",
      "Epoch 80/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.3555 - val_loss: 13.2230\n",
      "Epoch 81/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.3457 - val_loss: 11.6991\n",
      "Epoch 82/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.3479 - val_loss: 11.4561\n",
      "Epoch 83/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.3371 - val_loss: 11.4360\n",
      "Epoch 84/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.3449 - val_loss: 11.7271\n",
      "Epoch 85/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.3222 - val_loss: 11.6256\n",
      "Epoch 86/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.3193 - val_loss: 12.1207\n",
      "Epoch 87/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.3083 - val_loss: 11.3589\n",
      "Epoch 88/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.3022 - val_loss: 11.9882\n",
      "Epoch 89/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2939 - val_loss: 12.1678\n",
      "Epoch 90/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2840 - val_loss: 11.8306\n",
      "Epoch 91/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.2847 - val_loss: 11.4466\n",
      "Epoch 92/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2875 - val_loss: 11.5155\n",
      "Epoch 93/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2643 - val_loss: 11.6246\n",
      "Epoch 94/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2877 - val_loss: 11.5141\n",
      "Epoch 95/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2625 - val_loss: 11.5594\n",
      "Epoch 96/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2565 - val_loss: 11.3316\n",
      "Epoch 97/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2306 - val_loss: 11.8271\n",
      "Epoch 98/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.2422 - val_loss: 11.7290\n",
      "Epoch 99/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2504 - val_loss: 11.5333\n",
      "Epoch 100/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2330 - val_loss: 11.4191\n",
      "Epoch 101/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.2333 - val_loss: 11.3548\n",
      "Epoch 102/500\n",
      "3231/3231 [==============================] - 32s 10ms/step - loss: 11.2199 - val_loss: 11.5657\n",
      "Epoch 103/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.2077 - val_loss: 11.3582\n",
      "Epoch 104/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.2025 - val_loss: 11.3075\n",
      "Epoch 105/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.2129 - val_loss: 11.3148\n",
      "Epoch 106/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1955 - val_loss: 11.3449\n",
      "Epoch 107/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1784 - val_loss: 11.6231\n",
      "Epoch 108/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.2003 - val_loss: 12.1479\n",
      "Epoch 109/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1616 - val_loss: 11.3300\n",
      "Epoch 110/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1667 - val_loss: 11.6748\n",
      "Epoch 111/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1682 - val_loss: 11.3166\n",
      "Epoch 112/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1598 - val_loss: 11.4699\n",
      "Epoch 113/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1463 - val_loss: 11.4270\n",
      "Epoch 114/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1397 - val_loss: 11.4955\n",
      "Epoch 115/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1553 - val_loss: 11.2953\n",
      "Epoch 116/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1323 - val_loss: 11.6140\n",
      "Epoch 117/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1596 - val_loss: 11.4884\n",
      "Epoch 118/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1255 - val_loss: 11.2880\n",
      "Epoch 119/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1138 - val_loss: 11.4338\n",
      "Epoch 120/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 11.1019 - val_loss: 11.2800\n",
      "Epoch 121/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1088 - val_loss: 11.6665\n",
      "Epoch 122/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.1018 - val_loss: 11.3642\n",
      "Epoch 123/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 11.0978 - val_loss: 11.5813\n",
      "Epoch 124/500\n",
      "3231/3231 [==============================] - 37s 12ms/step - loss: 11.1084 - val_loss: 11.2817\n",
      "Epoch 125/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0979 - val_loss: 11.4662\n",
      "Epoch 126/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 11.0880 - val_loss: 11.4053\n",
      "Epoch 127/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0880 - val_loss: 11.4119\n",
      "Epoch 128/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0881 - val_loss: 11.6824\n",
      "Epoch 129/500\n",
      "3231/3231 [==============================] - 40s 13ms/step - loss: 11.0792 - val_loss: 12.3208\n",
      "Epoch 130/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0709 - val_loss: 11.4334\n",
      "Epoch 131/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0667 - val_loss: 11.6360\n",
      "Epoch 132/500\n",
      "3231/3231 [==============================] - 32s 10ms/step - loss: 11.0821 - val_loss: 12.3661\n",
      "Epoch 133/500\n",
      "3231/3231 [==============================] - 32s 10ms/step - loss: 11.0595 - val_loss: 11.3343\n",
      "Epoch 134/500\n",
      "3231/3231 [==============================] - 38s 12ms/step - loss: 11.0437 - val_loss: 11.3943\n",
      "Epoch 135/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0560 - val_loss: 11.5078\n",
      "Epoch 136/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0459 - val_loss: 11.1830\n",
      "Epoch 137/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0435 - val_loss: 11.1969\n",
      "Epoch 138/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0263 - val_loss: 11.3969\n",
      "Epoch 139/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0396 - val_loss: 11.2113\n",
      "Epoch 140/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0052 - val_loss: 11.2335\n",
      "Epoch 141/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0380 - val_loss: 11.2322\n",
      "Epoch 142/500\n",
      "3231/3231 [==============================] - 32s 10ms/step - loss: 11.0206 - val_loss: 11.3199\n",
      "Epoch 143/500\n",
      "3231/3231 [==============================] - 38s 12ms/step - loss: 11.0123 - val_loss: 11.2858\n",
      "Epoch 144/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0035 - val_loss: 11.3402\n",
      "Epoch 145/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 10.9973 - val_loss: 11.9350\n",
      "Epoch 146/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0112 - val_loss: 11.2377\n",
      "Epoch 147/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 10.9816 - val_loss: 11.4665\n",
      "Epoch 148/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 11.0126 - val_loss: 11.3280\n",
      "Epoch 149/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 10.9811 - val_loss: 11.4563\n",
      "Epoch 150/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 10.9895 - val_loss: 11.1883\n",
      "Epoch 151/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 10.9767 - val_loss: 11.3820\n",
      "Epoch 152/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 10.9713 - val_loss: 11.5894\n",
      "Epoch 153/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 10.9812 - val_loss: 11.2122\n",
      "Epoch 154/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 10.9841 - val_loss: 11.2177\n",
      "Epoch 155/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 10.9670 - val_loss: 11.2967\n",
      "Epoch 156/500\n",
      "3231/3231 [==============================] - 29s 9ms/step - loss: 10.9605 - val_loss: 11.2163\n",
      "Minimum validation loss: 11.183002471923828\n"
     ]
    }
   ],
   "source": [
    "#add early stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the model with more layers and neurons\n",
    "# Assuming your input shapes\n",
    "matrix_shape = (1148760, 60, 6)\n",
    "matrix_all_shape = (1148760, 12)\n",
    "\n",
    "# Define input layers for each matrix\n",
    "input_matrix = Input(shape=(matrix_shape[1], matrix_shape[2]), name='matrix_input')\n",
    "input_matrix_all = Input(shape=(matrix_all_shape[1],), name='matrix_input_all')\n",
    "\n",
    "# Flatten the input matrices\n",
    "flattened_matrix = Flatten()(input_matrix)\n",
    "flattened_matrix_all = input_matrix_all  # No need to flatten\n",
    "\n",
    "# Concatenate the flattened and non-flattened outputs\n",
    "concatenated_outputs = Concatenate()([flattened_matrix, flattened_matrix_all])\n",
    "\n",
    "\n",
    "dense1 = Dense(units=1024, activation = \"relu\")(concatenated_outputs)\n",
    "dense2 = Dense(units=1014, activation = \"relu\")(dense1)\n",
    "dense3 = Dense(units=1024, activation = \"relu\")(dense2)\n",
    "dense4 = Dense(units=512, activation = \"relu\")(dense3)\n",
    "output = Dense(units=1)(dense4)\n",
    "\n",
    "# Create the model\n",
    "model3 = Model(inputs=[input_matrix, input_matrix_all], outputs=output)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae'\n",
    ")\n",
    "# Train the model with your input and output data\n",
    "history = model3.fit([matrix_train, matrix_all_train], ccs_train, epochs=500, batch_size=256, validation_data=([matrix_val, matrix_all_val], ccs_val), callbacks=[early_stopping])\n",
    "\n",
    "history_df_3 = pd.DataFrame(history.history)\n",
    "print(\"Minimum validation loss: {}\".format(history_df_3['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7180/7180 [==============================] - 7s 966us/step\n"
     ]
    }
   ],
   "source": [
    "history_df_3.to_csv('history_3.csv', index=False) #save the history to a csv file for visualization\n",
    "# Predict CCS values test set\n",
    "ccs_test[\"Model3_predictions\"] = model3.predict((matrix_test, matrix_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_test.head()\n",
    "ccs_test.to_csv('ccs_test_model3.csv', index=False) #save the test set to a csv file for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 29.1184 - val_loss: 16.0350\n",
      "Epoch 2/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 24.8793 - val_loss: 20.2683\n",
      "Epoch 3/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 24.4736 - val_loss: 20.8097\n",
      "Epoch 4/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 24.1170 - val_loss: 13.8475\n",
      "Epoch 5/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.8298 - val_loss: 13.7631\n",
      "Epoch 6/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.6693 - val_loss: 15.0453\n",
      "Epoch 7/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.5504 - val_loss: 15.3630\n",
      "Epoch 8/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.4855 - val_loss: 13.4836\n",
      "Epoch 9/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.3947 - val_loss: 13.7568\n",
      "Epoch 10/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.2729 - val_loss: 14.9858\n",
      "Epoch 11/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.1838 - val_loss: 16.5249\n",
      "Epoch 12/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.1502 - val_loss: 16.5897\n",
      "Epoch 13/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.0760 - val_loss: 15.3401\n",
      "Epoch 14/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 23.0166 - val_loss: 12.5919\n",
      "Epoch 15/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.9236 - val_loss: 13.1240\n",
      "Epoch 16/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.8631 - val_loss: 12.4073\n",
      "Epoch 17/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.7674 - val_loss: 14.5083\n",
      "Epoch 18/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.6932 - val_loss: 13.7909\n",
      "Epoch 19/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.6719 - val_loss: 12.9013\n",
      "Epoch 20/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.6468 - val_loss: 12.9112\n",
      "Epoch 21/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.5527 - val_loss: 13.9726\n",
      "Epoch 22/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.5753 - val_loss: 13.2803\n",
      "Epoch 23/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.4860 - val_loss: 12.9252\n",
      "Epoch 24/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.4180 - val_loss: 14.8496\n",
      "Epoch 25/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.3885 - val_loss: 13.1281\n",
      "Epoch 26/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.3269 - val_loss: 12.9204\n",
      "Epoch 27/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.2976 - val_loss: 13.3920\n",
      "Epoch 28/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.2819 - val_loss: 12.6274\n",
      "Epoch 29/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.2340 - val_loss: 12.3846\n",
      "Epoch 30/500\n",
      "3231/3231 [==============================] - 31s 9ms/step - loss: 22.1727 - val_loss: 12.3033\n",
      "Epoch 31/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.1488 - val_loss: 12.8071\n",
      "Epoch 32/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.0761 - val_loss: 12.2457\n",
      "Epoch 33/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.0669 - val_loss: 12.5071\n",
      "Epoch 34/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 22.0307 - val_loss: 12.3769\n",
      "Epoch 35/500\n",
      "3231/3231 [==============================] - 31s 9ms/step - loss: 21.9261 - val_loss: 12.7030\n",
      "Epoch 36/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 21.9549 - val_loss: 13.4544\n",
      "Epoch 37/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 21.9065 - val_loss: 14.0607\n",
      "Epoch 38/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 21.8626 - val_loss: 12.3796\n",
      "Epoch 39/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 21.8183 - val_loss: 13.9343\n",
      "Epoch 40/500\n",
      "3231/3231 [==============================] - 34s 10ms/step - loss: 21.8062 - val_loss: 12.5748\n",
      "Epoch 41/500\n",
      "3231/3231 [==============================] - 35s 11ms/step - loss: 21.8007 - val_loss: 12.4425\n",
      "Epoch 42/500\n",
      "3231/3231 [==============================] - 39s 12ms/step - loss: 21.7077 - val_loss: 12.1299\n",
      "Epoch 43/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 21.6942 - val_loss: 12.3714\n",
      "Epoch 44/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 21.6081 - val_loss: 12.2987\n",
      "Epoch 45/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 21.5894 - val_loss: 12.4072\n",
      "Epoch 46/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 21.5856 - val_loss: 12.1600\n",
      "Epoch 47/500\n",
      "3231/3231 [==============================] - 43s 13ms/step - loss: 21.4942 - val_loss: 12.1906\n",
      "Epoch 48/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 21.4585 - val_loss: 13.0948\n",
      "Epoch 49/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 21.4086 - val_loss: 12.1979\n",
      "Epoch 50/500\n",
      "3231/3231 [==============================] - 38s 12ms/step - loss: 21.3471 - val_loss: 14.6490\n",
      "Epoch 51/500\n",
      "3231/3231 [==============================] - 31s 10ms/step - loss: 21.3943 - val_loss: 12.2437\n",
      "Epoch 52/500\n",
      "3231/3231 [==============================] - 31s 10ms/step - loss: 21.3723 - val_loss: 13.1558\n",
      "Epoch 53/500\n",
      "3231/3231 [==============================] - 40s 13ms/step - loss: 21.3242 - val_loss: 13.1632\n",
      "Epoch 54/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 21.2769 - val_loss: 12.2401\n",
      "Epoch 55/500\n",
      "3231/3231 [==============================] - 43s 13ms/step - loss: 21.2282 - val_loss: 12.8820\n",
      "Epoch 56/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 21.2291 - val_loss: 13.4877\n",
      "Epoch 57/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 21.1881 - val_loss: 12.9285\n",
      "Epoch 58/500\n",
      "3231/3231 [==============================] - 43s 13ms/step - loss: 21.1541 - val_loss: 12.4486\n",
      "Epoch 59/500\n",
      "3231/3231 [==============================] - 43s 13ms/step - loss: 21.1255 - val_loss: 12.3137\n",
      "Epoch 60/500\n",
      "3231/3231 [==============================] - 43s 13ms/step - loss: 21.0462 - val_loss: 12.4299\n",
      "Epoch 61/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 21.0891 - val_loss: 12.1133\n",
      "Epoch 62/500\n",
      "3231/3231 [==============================] - 31s 10ms/step - loss: 21.0723 - val_loss: 12.6463\n",
      "Epoch 63/500\n",
      "3231/3231 [==============================] - 33s 10ms/step - loss: 21.0620 - val_loss: 12.1300\n",
      "Epoch 64/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 20.9932 - val_loss: 12.8048\n",
      "Epoch 65/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.9663 - val_loss: 12.2169\n",
      "Epoch 66/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.9355 - val_loss: 12.0607\n",
      "Epoch 67/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.8932 - val_loss: 12.3243\n",
      "Epoch 68/500\n",
      "3231/3231 [==============================] - 43s 13ms/step - loss: 20.8741 - val_loss: 13.1391\n",
      "Epoch 69/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.8425 - val_loss: 13.0261\n",
      "Epoch 70/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.8154 - val_loss: 12.2033\n",
      "Epoch 71/500\n",
      "3231/3231 [==============================] - 43s 13ms/step - loss: 20.7190 - val_loss: 12.3921\n",
      "Epoch 72/500\n",
      "3231/3231 [==============================] - 37s 11ms/step - loss: 20.7263 - val_loss: 12.2005\n",
      "Epoch 73/500\n",
      "3231/3231 [==============================] - 31s 10ms/step - loss: 20.7301 - val_loss: 12.0033\n",
      "Epoch 74/500\n",
      "3231/3231 [==============================] - 31s 10ms/step - loss: 20.6610 - val_loss: 12.1299\n",
      "Epoch 75/500\n",
      "3231/3231 [==============================] - 31s 10ms/step - loss: 20.6243 - val_loss: 12.1337\n",
      "Epoch 76/500\n",
      "3231/3231 [==============================] - 31s 10ms/step - loss: 20.5715 - val_loss: 12.2778\n",
      "Epoch 77/500\n",
      "3231/3231 [==============================] - 32s 10ms/step - loss: 20.5573 - val_loss: 12.4694\n",
      "Epoch 78/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 20.5270 - val_loss: 12.1472\n",
      "Epoch 79/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 20.5108 - val_loss: 14.5289\n",
      "Epoch 80/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.4640 - val_loss: 12.4716\n",
      "Epoch 81/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.4676 - val_loss: 12.4397\n",
      "Epoch 82/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.4236 - val_loss: 12.7031\n",
      "Epoch 83/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.4015 - val_loss: 11.9067\n",
      "Epoch 84/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 20.3208 - val_loss: 12.2915\n",
      "Epoch 85/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 20.3514 - val_loss: 12.4931\n",
      "Epoch 86/500\n",
      "3231/3231 [==============================] - 40s 12ms/step - loss: 20.3065 - val_loss: 12.0816\n",
      "Epoch 87/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 20.2941 - val_loss: 12.4875\n",
      "Epoch 88/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 20.1923 - val_loss: 12.3409\n",
      "Epoch 89/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 20.0878 - val_loss: 12.1674\n",
      "Epoch 90/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 20.0440 - val_loss: 12.2489\n",
      "Epoch 91/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.9704 - val_loss: 12.2689\n",
      "Epoch 92/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.9472 - val_loss: 12.2168\n",
      "Epoch 93/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.8897 - val_loss: 12.2126\n",
      "Epoch 94/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.8912 - val_loss: 12.0679\n",
      "Epoch 95/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.8766 - val_loss: 12.0301\n",
      "Epoch 96/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.8223 - val_loss: 11.9996\n",
      "Epoch 97/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.7906 - val_loss: 12.4904\n",
      "Epoch 98/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.7744 - val_loss: 12.6927\n",
      "Epoch 99/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.6214 - val_loss: 12.8564\n",
      "Epoch 100/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.6162 - val_loss: 12.7036\n",
      "Epoch 101/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.6193 - val_loss: 14.3909\n",
      "Epoch 102/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.5488 - val_loss: 12.0397\n",
      "Epoch 103/500\n",
      "3231/3231 [==============================] - 30s 9ms/step - loss: 19.5173 - val_loss: 12.6299\n",
      "Minimum validation loss: 11.906652450561523\n"
     ]
    }
   ],
   "source": [
    "#adding dropout layers\n",
    "\n",
    "#add early stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "# Assuming your input shapes\n",
    "matrix_shape = (1148760, 60, 6)\n",
    "matrix_all_shape = (1148760, 12)\n",
    "\n",
    "# Define input layers for each matrix\n",
    "input_matrix = Input(shape=(matrix_shape[1], matrix_shape[2]), name='matrix_input')\n",
    "input_matrix_all = Input(shape=(matrix_all_shape[1],), name='matrix_input_all')\n",
    "\n",
    "# Flatten the input matrices\n",
    "flattened_matrix = Flatten()(input_matrix)\n",
    "flattened_matrix_all = input_matrix_all  # No need to flatten\n",
    "\n",
    "# Concatenate the flattened and non-flattened outputs\n",
    "concatenated_outputs = Concatenate()([flattened_matrix, flattened_matrix_all])\n",
    "\n",
    "\n",
    "dense1 = Dense(units=1024, activation = \"relu\")(concatenated_outputs)\n",
    "dropout1 = Dropout(0.3)(dense1) \n",
    "dense2 = Dense(units=1014, activation = \"relu\")(dense1)\n",
    "dropout2 = Dropout(0.3)(dense2) \n",
    "dense3 = Dense(units=1024, activation = \"relu\")(dense2)\n",
    "dropout3 = Dropout(0.3)(dense3)\n",
    "dense4 = Dense(units=512, activation = \"relu\")(dense3)\n",
    "dropout4 = Dropout(0.3)(dense4) \n",
    "output = Dense(units=1)(dropout4)\n",
    "\n",
    "# Create the model\n",
    "model4 = Model(inputs=[input_matrix, input_matrix_all], outputs=output)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae'\n",
    ")\n",
    "# Train the model with your input and output data\n",
    "history = model4.fit([matrix_train, matrix_all_train], ccs_train, epochs=500, batch_size=256, validation_data=([matrix_val, matrix_all_val], ccs_val), callbacks=[early_stopping])\n",
    "\n",
    "history_df_4 = pd.DataFrame(history.history)\n",
    "print(\"Minimum validation loss: {}\".format(history_df_4['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7180/7180 [==============================] - 11s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "history_df_4.to_csv('history_4.csv', index=False) #save the history to a csv file for visualization\n",
    "# Predict CCS values test set\n",
    "ccs_test[\"Model4_predictions\"] = model4.predict((matrix_test, matrix_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCS</th>\n",
       "      <th>Model2_predictions</th>\n",
       "      <th>Model3_predictions</th>\n",
       "      <th>Model4_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129919</th>\n",
       "      <td>420.248133</td>\n",
       "      <td>427.884583</td>\n",
       "      <td>423.535065</td>\n",
       "      <td>423.233276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129049</th>\n",
       "      <td>441.017200</td>\n",
       "      <td>430.113831</td>\n",
       "      <td>429.712219</td>\n",
       "      <td>431.340668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161312</th>\n",
       "      <td>550.032030</td>\n",
       "      <td>566.157043</td>\n",
       "      <td>564.284912</td>\n",
       "      <td>566.298706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15185</th>\n",
       "      <td>501.311247</td>\n",
       "      <td>500.421722</td>\n",
       "      <td>505.957703</td>\n",
       "      <td>503.284088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939427</th>\n",
       "      <td>520.231105</td>\n",
       "      <td>494.102081</td>\n",
       "      <td>493.030487</td>\n",
       "      <td>487.198242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CCS  Model2_predictions  Model3_predictions  \\\n",
       "129919   420.248133          427.884583          423.535065   \n",
       "1129049  441.017200          430.113831          429.712219   \n",
       "161312   550.032030          566.157043          564.284912   \n",
       "15185    501.311247          500.421722          505.957703   \n",
       "939427   520.231105          494.102081          493.030487   \n",
       "\n",
       "         Model4_predictions  \n",
       "129919           423.233276  \n",
       "1129049          431.340668  \n",
       "161312           566.298706  \n",
       "15185            503.284088  \n",
       "939427           487.198242  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccs_test.head()\n",
    "ccs_test.to_csv('ccs_test_model4.csv', index=False) #save the test set to a csv file for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3231/3231 [==============================] - 55s 17ms/step - loss: 77.0874 - val_loss: 14.8685\n",
      "Epoch 2/500\n",
      "3231/3231 [==============================] - 55s 17ms/step - loss: 17.3825 - val_loss: 15.6998\n",
      "Epoch 3/500\n",
      "3231/3231 [==============================] - 43s 13ms/step - loss: 16.5993 - val_loss: 27.9591\n",
      "Epoch 4/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 16.2750 - val_loss: 22.5686\n",
      "Epoch 5/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 15.9662 - val_loss: 25.2746\n",
      "Epoch 6/500\n",
      "3231/3231 [==============================] - 44s 14ms/step - loss: 15.7836 - val_loss: 25.1666\n",
      "Epoch 7/500\n",
      "3231/3231 [==============================] - 54s 17ms/step - loss: 15.7323 - val_loss: 25.5724\n",
      "Epoch 8/500\n",
      "3231/3231 [==============================] - 55s 17ms/step - loss: 15.5738 - val_loss: 25.5539\n",
      "Epoch 9/500\n",
      "3231/3231 [==============================] - 55s 17ms/step - loss: 15.5090 - val_loss: 26.2594\n",
      "Epoch 10/500\n",
      "3231/3231 [==============================] - 54s 17ms/step - loss: 15.5513 - val_loss: 22.3559\n",
      "Epoch 11/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 15.4674 - val_loss: 19.8638\n",
      "Epoch 12/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 15.4046 - val_loss: 29.5196\n",
      "Epoch 13/500\n",
      "3231/3231 [==============================] - 42s 13ms/step - loss: 15.3562 - val_loss: 28.0256\n",
      "Epoch 14/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 15.3015 - val_loss: 25.6079\n",
      "Epoch 15/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 15.3092 - val_loss: 25.4879\n",
      "Epoch 16/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 15.2591 - val_loss: 24.2722\n",
      "Epoch 17/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 15.1183 - val_loss: 24.9618\n",
      "Epoch 18/500\n",
      "3231/3231 [==============================] - 40s 13ms/step - loss: 15.1672 - val_loss: 22.2088\n",
      "Epoch 19/500\n",
      "3231/3231 [==============================] - 40s 13ms/step - loss: 15.1879 - val_loss: 19.9719\n",
      "Epoch 20/500\n",
      "3231/3231 [==============================] - 40s 13ms/step - loss: 15.1451 - val_loss: 28.0143\n",
      "Epoch 21/500\n",
      "3231/3231 [==============================] - 41s 13ms/step - loss: 15.0952 - val_loss: 25.3729\n",
      "Minimum validation loss: 14.868547439575195\n"
     ]
    }
   ],
   "source": [
    "#adding batch normalization\n",
    "\n",
    "# Define the model\n",
    "# Assuming your input shapes\n",
    "matrix_shape = (1148760, 60, 6)\n",
    "matrix_all_shape = (1148760, 12)\n",
    "\n",
    "# Define input layers for each matrix\n",
    "input_matrix = Input(shape=(matrix_shape[1], matrix_shape[2]), name='matrix_input')\n",
    "input_matrix_all = Input(shape=(matrix_all_shape[1],), name='matrix_input_all')\n",
    "\n",
    "# Flatten the input matrices\n",
    "flattened_matrix = Flatten()(input_matrix)\n",
    "flattened_matrix_all = input_matrix_all  # No need to flatten\n",
    "\n",
    "# Concatenate the flattened and non-flattened outputs\n",
    "concatenated_outputs = Concatenate()([flattened_matrix, flattened_matrix_all])\n",
    "\n",
    "# Add dense layers with dropout and batch normalization\n",
    "dense1 = Dense(units=1024, activation = \"relu\")(concatenated_outputs)\n",
    "dropout1 = Dropout(0.3)(dense1)  # Add dropout layer with 50% dropout rate\n",
    "batch_norm1 = BatchNormalization()(dropout1)  # Add batch normalization layer\n",
    "dense2 = Dense(units=1014, activation = \"relu\")(batch_norm1)\n",
    "dropout2 = Dropout(0.3)(dense2)  # Add dropout layer with 50% dropout rate\n",
    "batch_norm2 = BatchNormalization()(dropout2)  # Add batch normalization layer\n",
    "dense3 = Dense(units=1024, activation = \"relu\")(batch_norm2)\n",
    "dropout3 = Dropout(0.3)(dense3)  # Add dropout layer with 50% dropout rate\n",
    "batch_norm3 = BatchNormalization()(dropout3)  # Add batch normalization layer\n",
    "dense4 = Dense(units=512, activation = \"relu\")(batch_norm3)\n",
    "dropout4 = Dropout(0.3)(dense4)  # Add dropout layer with 50% dropout rate\n",
    "batch_norm4 = BatchNormalization()(dropout4)  # Add batch normalization layer\n",
    "output = Dense(units=1)(batch_norm4)\n",
    "\n",
    "# Create the model\n",
    "model5 = Model(inputs=[input_matrix, input_matrix_all], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model5.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae'\n",
    ")\n",
    "\n",
    "# Train the model with your input and output data\n",
    "history = model5.fit([matrix_train, matrix_all_train], ccs_train, epochs=500, batch_size=256, validation_data=([matrix_val, matrix_all_val], ccs_val), callbacks=[early_stopping])\n",
    "\n",
    "history_df_5 = pd.DataFrame(history.history)\n",
    "print(\"Minimum validation loss: {}\".format(history_df_5['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7180/7180 [==============================] - 7s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history_df_5.to_csv('history_5.csv', index=False) #save the history to a csv file for visualization\n",
    "# Predict CCS values test set\n",
    "ccs_test[\"Model5_predictions\"] = model5.predict((matrix_test, matrix_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCS</th>\n",
       "      <th>Model2_predictions</th>\n",
       "      <th>Model3_predictions</th>\n",
       "      <th>Model4_predictions</th>\n",
       "      <th>Model5_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129919</th>\n",
       "      <td>420.248133</td>\n",
       "      <td>427.884583</td>\n",
       "      <td>423.535065</td>\n",
       "      <td>423.233276</td>\n",
       "      <td>425.708954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129049</th>\n",
       "      <td>441.017200</td>\n",
       "      <td>430.113831</td>\n",
       "      <td>429.712219</td>\n",
       "      <td>431.340668</td>\n",
       "      <td>443.349762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161312</th>\n",
       "      <td>550.032030</td>\n",
       "      <td>566.157043</td>\n",
       "      <td>564.284912</td>\n",
       "      <td>566.298706</td>\n",
       "      <td>549.194092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15185</th>\n",
       "      <td>501.311247</td>\n",
       "      <td>500.421722</td>\n",
       "      <td>505.957703</td>\n",
       "      <td>503.284088</td>\n",
       "      <td>517.718506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939427</th>\n",
       "      <td>520.231105</td>\n",
       "      <td>494.102081</td>\n",
       "      <td>493.030487</td>\n",
       "      <td>487.198242</td>\n",
       "      <td>480.236694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CCS  Model2_predictions  Model3_predictions  \\\n",
       "129919   420.248133          427.884583          423.535065   \n",
       "1129049  441.017200          430.113831          429.712219   \n",
       "161312   550.032030          566.157043          564.284912   \n",
       "15185    501.311247          500.421722          505.957703   \n",
       "939427   520.231105          494.102081          493.030487   \n",
       "\n",
       "         Model4_predictions  Model5_predictions  \n",
       "129919           423.233276          425.708954  \n",
       "1129049          431.340668          443.349762  \n",
       "161312           566.298706          549.194092  \n",
       "15185            503.284088          517.718506  \n",
       "939427           487.198242          480.236694  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccs_test.head()\n",
    "ccs_test.to_csv('ccs_test_model5.csv', index=False) #save the test set to a csv file for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_test_model3 = pd.read_csv('/home/emmy/Notebooks2/output_FNN/ccs_test_model3.csv')\n",
    "\n",
    "\n",
    "\n",
    "if len(ccs_df.index) < 1e4:\n",
    "    set_alpha = 0.2\n",
    "    set_size = 3\n",
    "else:\n",
    "    set_alpha = 0.05\n",
    "    set_size = 1\n",
    "\n",
    "# Scatter plot the observations on the test set against the predictions on the same set\n",
    "plt.scatter(\n",
    "    ccs_test_model3[\"CCS\"],\n",
    "    ccs_test_model3[\"Model3_predictions\"],\n",
    "    alpha=set_alpha,\n",
    "    s=set_size,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Plot a diagonal the points should be one\n",
    "plt.plot([300,1100],[300,1100],c=\"grey\")\n",
    "\n",
    "legend = plt.legend()\n",
    "\n",
    "for lh in legend.legendHandles:\n",
    "    lh.set_sizes([25])\n",
    "    lh.set_alpha(1)\n",
    "\n",
    "# Get the predictions and calculate performance metrics\n",
    "predictions = ccs_test_model3[\"Model3_predictions\"]\n",
    "true_ccs = ccs_test_model3[\"CCS\"]\n",
    "mare = round(sum((abs(predictions-true_ccs)/true_ccs)*100)/len(predictions),3)\n",
    "pcc = round(pearsonr(predictions,true_ccs)[0],3)\n",
    "perc_95 = round(np.percentile((abs(predictions-true_ccs)/true_ccs)*100,95)*2,2)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(true_ccs, predictions)\n",
    "\n",
    "plt.title(f\"FNN - PCC: {pcc} - MARE: {mare}% - 95th percentile: {perc_95}% - MAE: {mae}\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.xlabel(\"Observed CCS (^2)\")\n",
    "plt.ylabel(\"Predicted CCS (^2)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310-vanilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
